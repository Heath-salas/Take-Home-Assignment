{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac41937-ee78-4ea4-b722-5950c0ef98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_tig.png: 480x640 1 person, 1 baseball bat, 380.5ms\n",
      "Speed: 3.3ms preprocess, 380.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_ryder.png: 416x640 15 persons, 328.2ms\n",
      "Speed: 3.2ms preprocess, 328.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_coachella.png: 416x640 13 persons, 1 traffic light, 2 backpacks, 1 umbrella, 336.2ms\n",
      "Speed: 2.6ms preprocess, 336.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_disney.png: 448x640 7 persons, 2 umbrellas, 1 tie, 1 teddy bear, 305.6ms\n",
      "Speed: 3.1ms preprocess, 305.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_surfer.png: 448x640 1 person, 1 surfboard, 429.6ms\n",
      "Speed: 3.5ms preprocess, 429.6ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_surfers.png: 448x640 2 persons, 2 surfboards, 335.6ms\n",
      "Speed: 3.0ms preprocess, 335.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_football.png: 384x640 13 persons, 2 baseball gloves, 349.5ms\n",
      "Speed: 3.8ms preprocess, 349.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_lambeau.png: 352x640 3 persons, 335.2ms\n",
      "Speed: 3.3ms preprocess, 335.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_snowboarder.png: 352x640 4 persons, 1 skis, 2 snowboards, 284.8ms\n",
      "Speed: 2.5ms preprocess, 284.8ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\heath\\A_kayak.png: 416x640 2 persons, 3 boats, 344.0ms\n",
      "Speed: 2.7ms preprocess, 344.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\heath\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>YOLO inference time (ms)</th>\n",
       "      <th>YOLO objects</th>\n",
       "      <th>YOLO avg confidence</th>\n",
       "      <th>RCNN inference time (ms)</th>\n",
       "      <th>RCNN objects</th>\n",
       "      <th>RCNN avg confidence</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>dominant colors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_tig.png</td>\n",
       "      <td>627.95</td>\n",
       "      <td>[(person, 0.9373472332954407), (baseball bat, ...</td>\n",
       "      <td>0.847</td>\n",
       "      <td>2360.73</td>\n",
       "      <td>[(person, 0.9979391694068909), (tennis racket,...</td>\n",
       "      <td>0.877</td>\n",
       "      <td>90.84</td>\n",
       "      <td>[(205, 39, 44), (40, 43, 33), (175, 162, 164)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_ryder.png</td>\n",
       "      <td>514.88</td>\n",
       "      <td>[(person, 0.9350208640098572), (person, 0.9327...</td>\n",
       "      <td>0.757</td>\n",
       "      <td>2775.58</td>\n",
       "      <td>[(person, 0.9995341300964355), (person, 0.9993...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>2011.94</td>\n",
       "      <td>[(198, 209, 168), (24, 31, 63), (119, 122, 98)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_coachella.png</td>\n",
       "      <td>555.40</td>\n",
       "      <td>[(umbrella, 0.9083945751190186), (backpack, 0....</td>\n",
       "      <td>0.437</td>\n",
       "      <td>2673.93</td>\n",
       "      <td>[(traffic light, 0.9569990634918213), (person,...</td>\n",
       "      <td>0.772</td>\n",
       "      <td>1446.86</td>\n",
       "      <td>[(154, 107, 93), (36, 20, 17), (207, 201, 209)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_disney.png</td>\n",
       "      <td>461.20</td>\n",
       "      <td>[(person, 0.9295040965080261), (person, 0.6147...</td>\n",
       "      <td>0.483</td>\n",
       "      <td>2538.34</td>\n",
       "      <td>[(person, 0.9995276927947998), (snowboard, 0.9...</td>\n",
       "      <td>0.764</td>\n",
       "      <td>305.64</td>\n",
       "      <td>[(27, 37, 39), (112, 111, 122), (165, 156, 150)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_surfer.png</td>\n",
       "      <td>689.69</td>\n",
       "      <td>[(person, 0.9259545207023621), (surfboard, 0.6...</td>\n",
       "      <td>0.767</td>\n",
       "      <td>3634.17</td>\n",
       "      <td>[(person, 0.9998679161071777), (cup, 0.9825803...</td>\n",
       "      <td>0.991</td>\n",
       "      <td>386.49</td>\n",
       "      <td>[(209, 225, 233), (23, 141, 160), (125, 188, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A_surfers.png</td>\n",
       "      <td>476.16</td>\n",
       "      <td>[(surfboard, 0.9503766894340515), (surfboard, ...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>3417.27</td>\n",
       "      <td>[(cup, 0.9991563558578491), (person, 0.9989651...</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1245.27</td>\n",
       "      <td>[(148, 186, 206), (43, 43, 36), (94, 114, 121)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A_football.png</td>\n",
       "      <td>613.19</td>\n",
       "      <td>[(person, 0.9415538311004639), (person, 0.9279...</td>\n",
       "      <td>0.614</td>\n",
       "      <td>3486.63</td>\n",
       "      <td>[(person, 0.9895995855331421), (person, 0.9890...</td>\n",
       "      <td>0.887</td>\n",
       "      <td>480.18</td>\n",
       "      <td>[(34, 54, 53), (188, 194, 199), (144, 136, 79)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A_lambeau.png</td>\n",
       "      <td>519.89</td>\n",
       "      <td>[(person, 0.5442403554916382), (person, 0.5089...</td>\n",
       "      <td>0.462</td>\n",
       "      <td>3500.16</td>\n",
       "      <td>[(person, 0.9413757920265198), (person, 0.9263...</td>\n",
       "      <td>0.648</td>\n",
       "      <td>7322.60</td>\n",
       "      <td>[(22, 34, 39), (141, 174, 186), (75, 94, 70)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A_snowboarder.png</td>\n",
       "      <td>448.50</td>\n",
       "      <td>[(person, 0.9479820728302002), (snowboard, 0.9...</td>\n",
       "      <td>0.762</td>\n",
       "      <td>3287.10</td>\n",
       "      <td>[(person, 0.999415397644043), (person, 0.99920...</td>\n",
       "      <td>0.890</td>\n",
       "      <td>1857.23</td>\n",
       "      <td>[(133, 160, 193), (50, 48, 54), (234, 234, 239)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A_kayak.png</td>\n",
       "      <td>502.81</td>\n",
       "      <td>[(person, 0.7988861203193665), (person, 0.7976...</td>\n",
       "      <td>0.617</td>\n",
       "      <td>3591.81</td>\n",
       "      <td>[(person, 0.9958186745643616), (person, 0.9947...</td>\n",
       "      <td>0.963</td>\n",
       "      <td>874.96</td>\n",
       "      <td>[(111, 160, 190), (170, 214, 242), (45, 73, 82)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image  YOLO inference time (ms)  \\\n",
       "0          A_tig.png                    627.95   \n",
       "1        A_ryder.png                    514.88   \n",
       "2    A_coachella.png                    555.40   \n",
       "3       A_disney.png                    461.20   \n",
       "4       A_surfer.png                    689.69   \n",
       "5      A_surfers.png                    476.16   \n",
       "6     A_football.png                    613.19   \n",
       "7      A_lambeau.png                    519.89   \n",
       "8  A_snowboarder.png                    448.50   \n",
       "9        A_kayak.png                    502.81   \n",
       "\n",
       "                                        YOLO objects  YOLO avg confidence  \\\n",
       "0  [(person, 0.9373472332954407), (baseball bat, ...                0.847   \n",
       "1  [(person, 0.9350208640098572), (person, 0.9327...                0.757   \n",
       "2  [(umbrella, 0.9083945751190186), (backpack, 0....                0.437   \n",
       "3  [(person, 0.9295040965080261), (person, 0.6147...                0.483   \n",
       "4  [(person, 0.9259545207023621), (surfboard, 0.6...                0.767   \n",
       "5  [(surfboard, 0.9503766894340515), (surfboard, ...                0.899   \n",
       "6  [(person, 0.9415538311004639), (person, 0.9279...                0.614   \n",
       "7  [(person, 0.5442403554916382), (person, 0.5089...                0.462   \n",
       "8  [(person, 0.9479820728302002), (snowboard, 0.9...                0.762   \n",
       "9  [(person, 0.7988861203193665), (person, 0.7976...                0.617   \n",
       "\n",
       "   RCNN inference time (ms)  \\\n",
       "0                   2360.73   \n",
       "1                   2775.58   \n",
       "2                   2673.93   \n",
       "3                   2538.34   \n",
       "4                   3634.17   \n",
       "5                   3417.27   \n",
       "6                   3486.63   \n",
       "7                   3500.16   \n",
       "8                   3287.10   \n",
       "9                   3591.81   \n",
       "\n",
       "                                        RCNN objects  RCNN avg confidence  \\\n",
       "0  [(person, 0.9979391694068909), (tennis racket,...                0.877   \n",
       "1  [(person, 0.9995341300964355), (person, 0.9993...                0.898   \n",
       "2  [(traffic light, 0.9569990634918213), (person,...                0.772   \n",
       "3  [(person, 0.9995276927947998), (snowboard, 0.9...                0.764   \n",
       "4  [(person, 0.9998679161071777), (cup, 0.9825803...                0.991   \n",
       "5  [(cup, 0.9991563558578491), (person, 0.9989651...                0.913   \n",
       "6  [(person, 0.9895995855331421), (person, 0.9890...                0.887   \n",
       "7  [(person, 0.9413757920265198), (person, 0.9263...                0.648   \n",
       "8  [(person, 0.999415397644043), (person, 0.99920...                0.890   \n",
       "9  [(person, 0.9958186745643616), (person, 0.9947...                0.963   \n",
       "\n",
       "   sharpness                                    dominant colors  \n",
       "0      90.84     [(205, 39, 44), (40, 43, 33), (175, 162, 164)]  \n",
       "1    2011.94    [(198, 209, 168), (24, 31, 63), (119, 122, 98)]  \n",
       "2    1446.86    [(154, 107, 93), (36, 20, 17), (207, 201, 209)]  \n",
       "3     305.64   [(27, 37, 39), (112, 111, 122), (165, 156, 150)]  \n",
       "4     386.49  [(209, 225, 233), (23, 141, 160), (125, 188, 2...  \n",
       "5    1245.27    [(148, 186, 206), (43, 43, 36), (94, 114, 121)]  \n",
       "6     480.18    [(34, 54, 53), (188, 194, 199), (144, 136, 79)]  \n",
       "7    7322.60      [(22, 34, 39), (141, 174, 186), (75, 94, 70)]  \n",
       "8    1857.23   [(133, 160, 193), (50, 48, 54), (234, 234, 239)]  \n",
       "9     874.96   [(111, 160, 190), (170, 214, 242), (45, 73, 82)]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# COCO class names for Faster R-CNN\n",
    "COCO_CLASSES = COCO_CLASSES = [\n",
    "    \"__background__\",\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\",\n",
    "    \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\",\n",
    "    \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
    "    \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "    \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\",\n",
    "    \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\",\n",
    "    \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
    "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
    "    \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\",\n",
    "    \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\",\n",
    "    \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\",\n",
    "    \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "\n",
    "# Transform for Faster R-CNN\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "################### PART B ##########################\n",
    "# SHARPNESS \n",
    "def image_sharpness(image_path):\n",
    "    \"\"\"\n",
    "    Returns the sharpness score using Laplacian variance.\n",
    "    Higher = sharper. Lower = blurrier.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return None\n",
    "    return cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "\n",
    "\n",
    "# DOMINANT COLORS\n",
    "def dominant_colors(image_path, k=3):\n",
    "    \"\"\"\n",
    "    Returns the top K dominant colors in RGB format.\n",
    "    Colors are returned as [(R,G,B), ...].\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_np = np.array(img)\n",
    "    pixels = img_np.reshape(-1, 3)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k, n_init='auto')\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    centers = kmeans.cluster_centers_.astype(int)\n",
    "    return [tuple(color) for color in centers]\n",
    "\n",
    "#####################################################\n",
    "\n",
    "results = []\n",
    "\n",
    "# MY 10 IMAGES\n",
    "images = ['A_tig.png', \n",
    "          'A_ryder.png', \n",
    "          'A_coachella.png', \n",
    "          'A_disney.png', \n",
    "          'A_surfer.png', \n",
    "          'A_surfers.png', \n",
    "          'A_football.png', \n",
    "          'A_lambeau.png', \n",
    "          'A_snowboarder.png', \n",
    "          'A_kayak.png'\n",
    "         ]\n",
    "\n",
    "# LOOP FOR EACH IMAGE \n",
    "for image_path in images:\n",
    "    \n",
    "\n",
    "    # YOLO SECTION \n",
    "    model1 = YOLO(\"yolov8m.pt\")\n",
    "    start_time = time.time()\n",
    "    yolo_results = model1.predict(image_path)\n",
    "    end_time = time.time()\n",
    "\n",
    "    yolo_time_ms = (end_time - start_time) * 1000\n",
    "    yolo_boxes = yolo_results[0].boxes\n",
    "    yolo_names = yolo_results[0].names\n",
    "\n",
    "    yolo_objects = []\n",
    "    yolo_confidences = []\n",
    "\n",
    "    for box in yolo_boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        class_name = yolo_names[cls_id]\n",
    "        conf = float(box.conf[0])\n",
    "        yolo_objects.append((class_name, conf))\n",
    "        yolo_confidences.append(conf)\n",
    "\n",
    "    yolo_avg_conf = sum(yolo_confidences) / len(yolo_confidences) if yolo_confidences else 0.0\n",
    "\n",
    "\n",
    "    # RCNN SECTION\n",
    "    model2 = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    model2.eval()\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        preds = model2([img_tensor])\n",
    "    end_time = time.time()\n",
    "\n",
    "    rcnn_time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "    pred_scores = preds[0][\"scores\"]\n",
    "    pred_labels = preds[0][\"labels\"]\n",
    "\n",
    "    rcnn_objects = []\n",
    "    rcnn_confidences = []\n",
    "\n",
    "    for score, label in zip(pred_scores, pred_labels):\n",
    "        if score >= 0.5:\n",
    "            class_name = COCO_CLASSES[label.item()]\n",
    "            conf = float(score)\n",
    "            rcnn_objects.append((class_name, conf))\n",
    "            rcnn_confidences.append(conf)\n",
    "\n",
    "    rcnn_avg_conf = sum(rcnn_confidences) / len(rcnn_confidences) if rcnn_confidences else 0.0\n",
    "\n",
    "    sharp = image_sharpness(image_path)\n",
    "    colors = dominant_colors(image_path, k=3)\n",
    "\n",
    "    # RESULTS\n",
    "    results.append({\n",
    "        \"image\": image_path,\n",
    "        \"YOLO inference time (ms)\": round(yolo_time_ms, 2),\n",
    "        \"YOLO objects\": yolo_objects,\n",
    "        \"YOLO avg confidence\": round(yolo_avg_conf, 3),\n",
    "        \"RCNN inference time (ms)\": round(rcnn_time_ms, 2),\n",
    "        \"RCNN objects\": rcnn_objects,\n",
    "        \"RCNN avg confidence\": round(rcnn_avg_conf, 3),\n",
    "        \"sharpness\": round(sharp, 2),\n",
    "        \"dominant colors\": colors\n",
    "    })\n",
    "\n",
    "\n",
    "# RESULTS CONVERTED INTO A \n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"image_model_results.xlsx\", index=False)\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e379314-7ecf-497d-9ca3-31e8a6ce5501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
